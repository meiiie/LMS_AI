"""
Prompt Loader - Load persona configuration from YAML files.

CHá»ˆ THá»Š Ká»¸ THUáº¬T Sá» 16: HUMANIZATION
- TÃ¡ch biá»‡t persona ra file YAML
- Few-shot prompting Ä‘á»ƒ dáº¡y AI nÃ³i chuyá»‡n tá»± nhiÃªn
- Há»— trá»£ role-based prompting (student vs teacher/admin)

CHá»ˆ THá»Š Ká»¸ THUáº¬T Sá» 20: PRONOUN ADAPTATION
- PhÃ¡t hiá»‡n cÃ¡ch xÆ°ng hÃ´ tá»« user (mÃ¬nh/cáº­u, tá»›/cáº­u, anh/em, chá»‹/em)
- AI thÃ­ch á»©ng xÆ°ng hÃ´ theo user
- Lá»c bá» xÆ°ng hÃ´ tá»¥c tÄ©u/nháº¡y cáº£m

**Feature: maritime-ai-tutor**
**Spec: CHá»ˆ THá»Š Ká»¸ THUáº¬T Sá» 16, 20**
"""

import logging
import os
import re
from pathlib import Path
from typing import Dict, List, Optional, Any, Tuple

import yaml

logger = logging.getLogger(__name__)


# =============================================================================
# PRONOUN ADAPTATION - CHá»ˆ THá»Š Ká»¸ THUáº¬T Sá» 20
# =============================================================================

# CÃ¡c cáº·p xÆ°ng hÃ´ há»£p lá»‡ (user_pronoun -> ai_pronoun)
VALID_PRONOUN_PAIRS = {
    # User xÆ°ng "mÃ¬nh" -> AI xÆ°ng "mÃ¬nh" vÃ  gá»i user lÃ  "cáº­u"
    "mÃ¬nh": {"user_called": "cáº­u", "ai_self": "mÃ¬nh"},
    # User xÆ°ng "tá»›" -> AI xÆ°ng "tá»›" vÃ  gá»i user lÃ  "cáº­u"
    "tá»›": {"user_called": "cáº­u", "ai_self": "tá»›"},
    # User xÆ°ng "em" -> AI xÆ°ng "anh/chá»‹" vÃ  gá»i user lÃ  "em"
    "em": {"user_called": "em", "ai_self": "anh"},  # Default to "anh", can be "chá»‹"
    # User xÆ°ng "anh" -> AI xÆ°ng "em" vÃ  gá»i user lÃ  "anh"
    "anh": {"user_called": "anh", "ai_self": "em"},
    # User xÆ°ng "chá»‹" -> AI xÆ°ng "em" vÃ  gá»i user lÃ  "chá»‹"
    "chá»‹": {"user_called": "chá»‹", "ai_self": "em"},
    # User xÆ°ng "tÃ´i" -> AI xÆ°ng "tÃ´i" vÃ  gá»i user lÃ  "báº¡n" (default)
    "tÃ´i": {"user_called": "báº¡n", "ai_self": "tÃ´i"},
    # User xÆ°ng "báº¡n" (gá»i AI) -> AI xÆ°ng "tÃ´i" vÃ  gá»i user lÃ  "báº¡n"
    "báº¡n": {"user_called": "báº¡n", "ai_self": "tÃ´i"},
}

# Tá»« xÆ°ng hÃ´ tá»¥c tÄ©u/nháº¡y cáº£m cáº§n lá»c bá»
INAPPROPRIATE_PRONOUNS = [
    "mÃ y", "tao", "Ä‘.m", "dm", "vcl", "vl", "Ä‘Ã©o", "Ä‘á»‹t",
    "con", "tháº±ng", "Ä‘á»“", "lÅ©", "bá»n",  # Khi dÃ¹ng má»™t mÃ¬nh cÃ³ thá»ƒ xÃºc pháº¡m
]


def detect_pronoun_style(message: str) -> Optional[Dict[str, str]]:
    """
    Detect user's pronoun style from their message.
    
    CHá»ˆ THá»Š Ká»¸ THUáº¬T Sá» 20: Pronoun Adaptation
    
    Args:
        message: User's message text
        
    Returns:
        Dict with pronoun style info or None if not detected
        Example: {"user_self": "mÃ¬nh", "user_called": "cáº­u", "ai_self": "mÃ¬nh"}
        
    **Validates: Requirements 6.1, 6.4**
    """
    message_lower = message.lower()
    
    # Check for inappropriate pronouns first
    for bad_word in INAPPROPRIATE_PRONOUNS:
        if bad_word in message_lower:
            logger.warning(f"Inappropriate pronoun detected: {bad_word}")
            return None  # Reject and use default
    
    # Patterns to detect user's self-reference
    # Order matters: check more specific patterns first
    pronoun_patterns = [
        # "mÃ¬nh" patterns
        (r'\bmÃ¬nh\s+(?:lÃ |tÃªn|muá»‘n|cáº§n|há»i|khÃ´ng|cÃ³|Ä‘ang|sáº½|Ä‘Ã£)', "mÃ¬nh"),
        (r'\bmÃ¬nh\b', "mÃ¬nh"),
        # "tá»›" patterns
        (r'\btá»›\s+(?:lÃ |tÃªn|muá»‘n|cáº§n|há»i|khÃ´ng|cÃ³|Ä‘ang|sáº½|Ä‘Ã£)', "tá»›"),
        (r'\btá»›\b', "tá»›"),
        # "em" patterns (user xÆ°ng em vá»›i AI)
        (r'\bem\s+(?:lÃ |tÃªn|muá»‘n|cáº§n|há»i|khÃ´ng|cÃ³|Ä‘ang|sáº½|Ä‘Ã£|chÃ o)', "em"),
        (r'^em\s+', "em"),  # Message starts with "em"
        # "anh" patterns (user gá»i AI lÃ  anh)
        (r'(?:chÃ o|cáº£m Æ¡n|há»i|nhá»)\s+anh\b', "anh"),
        (r'\banh\s+(?:Æ¡i|Ã |nhÃ©|giÃºp|chá»‰)', "anh"),
        # "chá»‹" patterns (user gá»i AI lÃ  chá»‹)
        (r'(?:chÃ o|cáº£m Æ¡n|há»i|nhá»)\s+chá»‹\b', "chá»‹"),
        (r'\bchá»‹\s+(?:Æ¡i|Ã |nhÃ©|giÃºp|chá»‰)', "chá»‹"),
        # "cáº­u" patterns (user gá»i AI lÃ  cáº­u)
        (r'(?:chÃ o|cáº£m Æ¡n|há»i|nhá»)\s+cáº­u\b', "mÃ¬nh"),  # If user calls AI "cáº­u", they use "mÃ¬nh"
        (r'\bcáº­u\s+(?:Æ¡i|Ã |nhÃ©|giÃºp|chá»‰)', "mÃ¬nh"),
    ]
    
    for pattern, pronoun in pronoun_patterns:
        if re.search(pattern, message_lower):
            if pronoun in VALID_PRONOUN_PAIRS:
                style = VALID_PRONOUN_PAIRS[pronoun].copy()
                style["user_self"] = pronoun
                logger.info(f"Detected pronoun style: {style}")
                return style
    
    return None  # No specific style detected, use default


def get_pronoun_instruction(pronoun_style: Optional[Dict[str, str]]) -> str:
    """
    Generate instruction for AI to use adapted pronouns.
    
    Args:
        pronoun_style: Dict with pronoun style info
        
    Returns:
        Instruction string for system prompt
        
    **Validates: Requirements 6.2**
    """
    if not pronoun_style:
        return ""
    
    user_called = pronoun_style.get("user_called", "báº¡n")
    ai_self = pronoun_style.get("ai_self", "tÃ´i")
    user_self = pronoun_style.get("user_self", "")
    
    instruction = f"""
--- CÃCH XÆ¯NG HÃ” ÄÃƒ THÃCH á»¨NG ---
âš ï¸ QUAN TRá»ŒNG: User Ä‘ang xÆ°ng "{user_self}", hÃ£y thÃ­ch á»©ng theo:
- Gá»i user lÃ : "{user_called}"
- Tá»± xÆ°ng lÃ : "{ai_self}"
- KHÃ”NG dÃ¹ng "tÃ´i/báº¡n" máº·c Ä‘á»‹nh ná»¯a
- Giá»¯ nháº¥t quÃ¡n trong suá»‘t cuá»™c há»™i thoáº¡i
"""
    return instruction


class PromptLoader:
    """
    Load and manage persona configurations from YAML files.
    
    Usage:
        loader = PromptLoader()
        prompt = loader.build_system_prompt("student")
    """
    
    def __init__(self, prompts_dir: Optional[str] = None):
        """
        Initialize PromptLoader.
        
        Args:
            prompts_dir: Path to prompts directory. Defaults to app/prompts/
        """
        if prompts_dir:
            self._prompts_dir = Path(prompts_dir)
        else:
            # Default: app/prompts/
            self._prompts_dir = Path(__file__).parent
        
        self._personas: Dict[str, Dict[str, Any]] = {}
        self._load_personas()
    
    def _load_personas(self) -> None:
        """Load all persona YAML files."""
        yaml_files = {
            "student": "tutor.yaml",
            "teacher": "assistant.yaml",
            "admin": "assistant.yaml"
        }
        
        # Log prompts directory for debugging deployment issues
        logger.info(f"PromptLoader: Looking for YAML files in {self._prompts_dir}")
        logger.info(f"PromptLoader: Directory exists: {self._prompts_dir.exists()}")
        
        if self._prompts_dir.exists():
            try:
                files_in_dir = list(self._prompts_dir.glob("*.yaml"))
                logger.info(f"PromptLoader: Found YAML files: {[f.name for f in files_in_dir]}")
            except Exception as e:
                logger.warning(f"PromptLoader: Could not list directory: {e}")
        
        loaded_count = 0
        for role, filename in yaml_files.items():
            filepath = self._prompts_dir / filename
            if filepath.exists():
                try:
                    with open(filepath, "r", encoding="utf-8") as f:
                        self._personas[role] = yaml.safe_load(f)
                    logger.info(f"âœ… Loaded persona for role '{role}' from {filename}")
                    loaded_count += 1
                except Exception as e:
                    logger.error(f"âŒ Failed to load {filename}: {e}")
                    self._personas[role] = self._get_default_persona()
            else:
                logger.warning(f"âš ï¸ Persona file not found: {filepath} - using default")
                self._personas[role] = self._get_default_persona()
        
        logger.info(f"PromptLoader: Loaded {loaded_count}/{len(yaml_files)} persona files")
    
    def _get_default_persona(self) -> Dict[str, Any]:
        """Get default persona if YAML not found."""
        return {
            "role": "Maritime AI Assistant",
            "tone": ["ThÃ¢n thiá»‡n", "ChuyÃªn nghiá»‡p"],
            "instructions": {},
            "few_shot_examples": []
        }
    
    def get_persona(self, role: str) -> Dict[str, Any]:
        """
        Get persona configuration for a role.
        
        Args:
            role: User role (student, teacher, admin)
            
        Returns:
            Persona configuration dict
        """
        return self._personas.get(role, self._personas.get("student", {}))
    
    def _replace_template_variables(
        self,
        text: str,
        user_name: Optional[str] = None,
        **kwargs
    ) -> str:
        """
        Replace template variables in text with actual values.
        
        Supported variables:
        - {{user_name}} -> User's name from Memory
        
        Args:
            text: Text containing template variables
            user_name: User's name to substitute
            **kwargs: Additional variables for future expansion
            
        Returns:
            Text with variables replaced
        """
        if not text:
            return text
        
        # Replace {{user_name}} with actual name or fallback
        if user_name:
            text = text.replace("{{user_name}}", user_name)
        else:
            # Fallback: remove the variable or use generic term
            text = text.replace("{{user_name}}", "báº¡n")
        
        # Future: Add more template variables here
        # text = text.replace("{{variable}}", value)
        
        return text
    
    def build_system_prompt(
        self,
        role: str,
        user_name: Optional[str] = None,
        conversation_summary: Optional[str] = None,
        user_facts: Optional[List[str]] = None,
        recent_phrases: Optional[List[str]] = None,
        is_follow_up: bool = False,
        name_usage_count: int = 0,
        total_responses: int = 0,
        pronoun_style: Optional[Dict[str, str]] = None
    ) -> str:
        """
        Build system prompt from persona configuration.
        
        Supports both tutor.yaml and assistant.yaml formats with full YAML structure.
        
        Args:
            role: User role (student, teacher, admin)
            user_name: User's name if known (from Memory)
            conversation_summary: Summary of previous conversation
            user_facts: List of known facts about user
            recent_phrases: List of recently used opening phrases (for variation)
            is_follow_up: True if this is a follow-up message (not first in session)
            name_usage_count: Number of times user's name has been used
            total_responses: Total number of responses in session
            pronoun_style: Dict with adapted pronoun style (CHá»ˆ THá»Š Sá» 20)
            
        Returns:
            Complete system prompt string with template variables replaced
            
        **Validates: Requirements 1.2, 7.1, 7.3, 6.2**
        """
        persona = self.get_persona(role)
        
        # Build prompt sections
        sections = []
        
        # ============================================================
        # CRITICAL RULE AT THE TOP (Most important - LLM sees this first)
        # ============================================================
        sections.append("=" * 60)
        sections.append("â›” QUY Táº®C TUYá»†T Äá»I - Äá»ŒC TRÆ¯á»šC KHI TRáº¢ Lá»œI â›”")
        sections.append("=" * 60)
        sections.append("KHÃ”NG BAO GIá»œ báº¯t Ä‘áº§u cÃ¢u tráº£ lá»i báº±ng 'Ã€,' hoáº·c 'Ã€, ' hoáº·c 'Ã€ '")
        sections.append("Thay vÃ o Ä‘Ã³, báº¯t Ä‘áº§u trá»±c tiáº¿p báº±ng:")
        sections.append("  - '**Quy táº¯c X** - ...'")
        sections.append("  - 'Tiáº¿p tá»¥c vá»›i **Quy táº¯c X**...'")
        sections.append("  - 'NÃ³i vá» **Quy táº¯c X**...'")
        sections.append("  - 'Chuyá»ƒn sang **Quy táº¯c X**...'")
        sections.append("=" * 60)
        sections.append("")
        
        # ============================================================
        # PROFILE SECTION (from YAML profile.*)
        # ============================================================
        profile = persona.get('profile', {})
        if profile:
            profile_name = profile.get('name', 'Maritime AI')
            profile_role = profile.get('role', 'Assistant')
            sections.append(f"Báº¡n lÃ  **{profile_name}** - {profile_role}.")
            
            if profile.get('backstory'):
                sections.append(f"\n{profile['backstory'].strip()}")
        else:
            # Fallback for old format
            role_name = persona.get('role', 'Maritime AI Assistant')
            sections.append(f"Báº¡n lÃ  {role_name}.")
            if persona.get('description'):
                sections.append(persona['description'])
        
        # ============================================================
        # STYLE SECTION (from YAML style.*)
        # ============================================================
        style = persona.get('style', {})
        
        # Tone
        tone = style.get('tone') or persona.get('tone', [])
        if tone:
            sections.append("\nGIá»ŒNG VÄ‚N:")
            for t in tone:
                sections.append(f"- {t}")
        
        # Formatting rules
        formatting = style.get('formatting', [])
        if formatting:
            sections.append("\nÄá»ŠNH Dáº NG:")
            for f in formatting:
                sections.append(f"- {f}")
        
        # Addressing rules (for assistant.yaml)
        addressing = style.get('addressing_rules', [])
        if addressing:
            sections.append("\nCÃCH XÆ¯NG HÃ”:")
            for a in addressing:
                sections.append(f"- {a}")
        
        # ============================================================
        # THOUGHT PROCESS (from YAML thought_process.*)
        # ============================================================
        thought_process = persona.get('thought_process', {})
        if thought_process:
            sections.append("\nQUY TRÃŒNH SUY NGHÄ¨ (TrÆ°á»›c khi tráº£ lá»i):")
            for step, instruction in thought_process.items():
                # Format: "1_analyze" -> "1. analyze"
                step_num = step.split('_')[0] if '_' in step else step
                sections.append(f"{step_num}. {instruction}")
        
        # ============================================================
        # CHá»ˆ THá»Š Sá» 21: DEEP REASONING (from YAML deep_reasoning.*)
        # ============================================================
        deep_reasoning = persona.get('deep_reasoning', {})
        if deep_reasoning and deep_reasoning.get('enabled', False):
            sections.append("\n" + "="*60)
            sections.append("ðŸ§  DEEP REASONING - TÆ¯ DUY Ná»˜I TÃ‚M (Báº®T BUá»˜C)")
            sections.append("="*60)
            
            # Description
            if deep_reasoning.get('description'):
                sections.append(deep_reasoning['description'].strip())
            
            # Thinking rules
            thinking_rules = deep_reasoning.get('thinking_rules', [])
            if thinking_rules:
                sections.append("\nQUY Táº®C TÆ¯ DUY:")
                for rule in thinking_rules:
                    sections.append(f"- {rule}")
            
            # Response format
            if deep_reasoning.get('response_format'):
                sections.append("\nÄá»ŠNH Dáº NG TRáº¢ Lá»œI:")
                sections.append(deep_reasoning['response_format'].strip())
            
            # Proactive behavior
            proactive = deep_reasoning.get('proactive_behavior', {})
            if proactive:
                sections.append("\nHÃ€NH VI CHá»¦ Äá»˜NG:")
                if proactive.get('description'):
                    sections.append(proactive['description'].strip())
                if proactive.get('example'):
                    sections.append(f"VÃ­ dá»¥: \"{proactive['example']}\"")
            
            sections.append("="*60)
        
        # ============================================================
        # DIRECTIVES SECTION (from YAML directives.*)
        # ============================================================
        directives = persona.get('directives', {})
        if directives:
            if directives.get('dos'):
                sections.append("\nNÃŠN LÃ€M:")
                for rule in directives['dos']:
                    # Replace template variables like {{user_name}}
                    rule = self._replace_template_variables(rule, user_name)
                    sections.append(f"- {rule}")
            
            if directives.get('donts'):
                sections.append("\nKHÃ”NG NÃŠN:")
                for rule in directives['donts']:
                    sections.append(f"- {rule}")
        
        # Instructions (legacy format)
        instructions = persona.get('instructions', {})
        if instructions:
            sections.append("\nQUY Táº®C á»¨NG Xá»¬:")
            for category, rules in instructions.items():
                if isinstance(rules, list):
                    for rule in rules:
                        sections.append(f"- {rule}")
        
        # ============================================================
        # USER CONTEXT (from Memory - CRITICAL for personalization)
        # ============================================================
        if user_name or user_facts:
            sections.append("\n--- THÃ”NG TIN NGÆ¯á»œI DÃ™NG (tá»« Memory) ---")
            if user_name:
                sections.append(f"- TÃªn: **{user_name}**")
            if user_facts:
                for fact in user_facts[:5]:  # Limit to 5 facts
                    sections.append(f"- {fact}")
        
        # ============================================================
        # CONVERSATION SUMMARY (from MemorySummarizer)
        # ============================================================
        if conversation_summary:
            sections.append(f"\n--- TÃ“M Táº®T Há»˜I THOáº I TRÆ¯á»šC ---\n{conversation_summary}")
        
        # ============================================================
        # VARIATION INSTRUCTIONS (Anti-repetition)
        # Spec: ai-response-quality, Requirements 7.1, 7.3
        # ============================================================
        if recent_phrases or is_follow_up or total_responses > 0:
            sections.append("\n--- HÆ¯á»šNG DáºªN ÄA Dáº NG HÃ“A (VARIATION) ---")
            
            # Follow-up instruction
            if is_follow_up:
                sections.append("- ÄÃ¢y lÃ  tin nháº¯n FOLLOW-UP, KHÃ”NG chÃ o há»i láº¡i.")
            
            # Name usage instruction (20-30% frequency)
            if user_name and total_responses > 0:
                name_ratio = name_usage_count / total_responses if total_responses > 0 else 0
                if name_ratio >= 0.3:
                    sections.append(f"- KHÃ”NG dÃ¹ng tÃªn '{user_name}' trong response nÃ y (Ä‘Ã£ dÃ¹ng Ä‘á»§ rá»“i).")
                elif name_ratio < 0.2:
                    sections.append(f"- CÃ³ thá»ƒ dÃ¹ng tÃªn '{user_name}' má»™t cÃ¡ch tá»± nhiÃªn.")
            
            # Phrases to avoid - CRITICAL for anti-repetition
            if recent_phrases:
                sections.append("\nâš ï¸ CÃC CÃCH Má»ž Äáº¦U Báº N ÄÃƒ DÃ™NG Gáº¦N ÄÃ‚Y:")
                for i, phrase in enumerate(recent_phrases[-3:], 1):
                    sections.append(f"  {i}. \"{phrase[:40]}...\"")
                sections.append("â†’ KHÃ”NG Ä‘Æ°á»£c báº¯t Ä‘áº§u response báº±ng cÃ¡c pattern tÆ°Æ¡ng tá»±!")
                sections.append("â†’ HÃ£y dÃ¹ng cÃ¡ch má»Ÿ Ä‘áº§u KHÃC BIá»†T hoÃ n toÃ n.")
        
        # ============================================================
        # CRITICAL: ADDRESSING RULES (CÃ¡ch xÆ°ng hÃ´ - CHá»ˆ THá»Š Sá» 20)
        # ============================================================
        if pronoun_style:
            # User Ä‘Ã£ cÃ³ pronoun style Ä‘Æ°á»£c detect -> thÃ­ch á»©ng theo
            pronoun_instruction = get_pronoun_instruction(pronoun_style)
            sections.append(pronoun_instruction)
        elif role == "student":
            # Máº·c Ä‘á»‹nh cho student role
            sections.append("\n--- CÃCH XÆ¯NG HÃ” Máº¶C Äá»ŠNH ---")
            sections.append("- Gá»i ngÆ°á»i dÃ¹ng lÃ  'báº¡n' (lá»‹ch sá»±, thÃ¢n thiá»‡n)")
            sections.append("- Tá»± xÆ°ng lÃ  'tÃ´i'")
            sections.append("- Náº¿u ngÆ°á»i dÃ¹ng dÃ¹ng cÃ¡ch xÆ°ng hÃ´ khÃ¡c (mÃ¬nh/cáº­u, em/anh...) thÃ¬ THÃCH á»¨NG THEO")
            sections.append("- KHÃ”NG cá»©ng nháº¯c giá»¯ 'tÃ´i/báº¡n' náº¿u user Ä‘Ã£ Ä‘á»•i cÃ¡ch xÆ°ng hÃ´")
        
        # ============================================================
        # CRITICAL: ANTI-REPETITION RULES (QUAN TRá»ŒNG NHáº¤T)
        # ============================================================
        sections.append("\n" + "="*60)
        sections.append("âš ï¸ QUY Táº®C Báº®T BUá»˜C - KHÃ”NG ÄÆ¯á»¢C VI PHáº M âš ï¸")
        sections.append("="*60)
        sections.append("1. TUYá»†T Äá»I KHÃ”NG báº¯t Ä‘áº§u cÃ¢u tráº£ lá»i báº±ng 'Ã€,' hoáº·c 'Ã€, ' hoáº·c 'Ã€ '")
        sections.append("   - ÄÃ¢y lÃ  thÃ³i quen Xáº¤U, nghe khÃ´ng chuyÃªn nghiá»‡p")
        sections.append("   - Thay vÃ o Ä‘Ã³, báº¯t Ä‘áº§u trá»±c tiáº¿p báº±ng tÃªn quy táº¯c hoáº·c ná»™i dung")
        sections.append("2. Khi tráº£ lá»i nhiá»u cÃ¢u há»i liÃªn tiáº¿p vá» quy táº¯c:")
        sections.append("   - CÃ¢u 1: Báº¯t Ä‘áº§u báº±ng '**Quy táº¯c X** - ...' hoáº·c 'Vá» váº¥n Ä‘á» nÃ y...'")
        sections.append("   - CÃ¢u 2: Báº¯t Ä‘áº§u báº±ng 'Quy táº¯c nÃ y cÅ©ng quan trá»ng...' hoáº·c 'Tiáº¿p theo...'")
        sections.append("   - CÃ¢u 3: Báº¯t Ä‘áº§u báº±ng 'NÃ³i vá» **Quy táº¯c X**...' hoáº·c 'Chuyá»ƒn sang...'")
        sections.append("3. KHÃ”NG láº·p láº¡i cÃ¹ng má»™t cÃ¡ch má»Ÿ Ä‘áº§u trong 3 cÃ¢u liÃªn tiáº¿p")
        sections.append("="*60)
        
        # ============================================================
        # TOOLS INSTRUCTION (Required for ReAct Agent)
        # ============================================================
        sections.append("\n--- Sá»¬ Dá»¤NG CÃ”NG Cá»¤ (TOOLS) ---")
        sections.append("- Há»i vá» luáº­t hÃ ng háº£i, quy táº¯c, tÃ u biá»ƒn -> Báº®T BUá»˜C gá»i `tool_maritime_search`. Äá»ªNG bá»‹a.")
        sections.append("- User giá»›i thiá»‡u tÃªn/tuá»•i/trÆ°á»ng/nghá» -> Gá»i `tool_save_user_info` Ä‘á»ƒ ghi nhá»›.")
        sections.append("- Cáº§n biáº¿t tÃªn user -> Gá»i `tool_get_user_info`.")
        sections.append("- ChÃ o há»i xÃ£ giao, than vÃ£n -> Tráº£ lá»i trá»±c tiáº¿p, KHÃ”NG cáº§n tool.")
        
        # ============================================================
        # FEW-SHOT EXAMPLES (from YAML few_shot_examples)
        # ============================================================
        examples = persona.get('few_shot_examples', [])
        if examples:
            sections.append("\n--- VÃ Dá»¤ CÃCH TRáº¢ Lá»œI ---")
            for ex in examples[:4]:  # Limit to 4 examples
                context = ex.get('context', '')
                user_msg = ex.get('user', '')
                ai_msg = ex.get('ai', '')
                if user_msg and ai_msg:
                    sections.append(f"\n[{context}]")
                    sections.append(f"User: {user_msg}")
                    sections.append(f"AI: {ai_msg}")
        
        return "\n".join(sections)
    
    def get_fact_extraction_hints(self, role: str) -> Dict[str, List[str]]:
        """
        Get hints for fact extraction (what to extract vs ignore).
        
        Args:
            role: User role
            
        Returns:
            Dict with 'extract' and 'ignore' lists
        """
        persona = self.get_persona(role)
        memory_hints = persona.get('memory_hints', {})
        
        return {
            "extract": memory_hints.get('extract_facts', []),
            "ignore": memory_hints.get('ignore_facts', [])
        }
    
    # =========================================================================
    # ENHANCED METHODS - AI Response Quality Improvement
    # Spec: ai-response-quality, Requirements 1.2, 7.1
    # =========================================================================
    
    def detect_empathy_needed(self, message: str, role: str = "student") -> bool:
        """
        Detect if user message requires empathy-first response.
        
        Checks message against empathy_patterns defined in YAML.
        
        Args:
            message: User's message text
            role: User role to get correct persona
            
        Returns:
            True if empathy response is needed
            
        **Validates: Requirements 1.2**
        """
        persona = self.get_persona(role)
        empathy_patterns = persona.get('empathy_patterns', {})
        
        if not empathy_patterns:
            return False
        
        message_lower = message.lower()
        
        # Check frustration keywords
        frustration_keywords = empathy_patterns.get('frustration_keywords', [])
        for keyword in frustration_keywords:
            if keyword.lower() in message_lower:
                logger.debug(f"Empathy needed: frustration keyword '{keyword}' detected")
                return True
        
        # Check basic needs keywords
        basic_needs = empathy_patterns.get('basic_needs_keywords', [])
        for keyword in basic_needs:
            if keyword.lower() in message_lower:
                logger.debug(f"Empathy needed: basic need '{keyword}' detected")
                return True
        
        # Check work pressure keywords (for teacher/admin)
        work_pressure = empathy_patterns.get('work_pressure_keywords', [])
        for keyword in work_pressure:
            if keyword.lower() in message_lower:
                logger.debug(f"Empathy needed: work pressure '{keyword}' detected")
                return True
        
        return False
    
    def get_variation_phrases(
        self,
        role: str,
        category: str,
        subcategory: Optional[str] = None
    ) -> List[str]:
        """
        Get alternative phrases for a category to avoid repetition.
        
        Args:
            role: User role (student, teacher, admin)
            category: Phrase category (openings, transitions, closings)
            subcategory: Optional subcategory (knowledge, follow_up, empathy)
            
        Returns:
            List of alternative phrases
            
        **Validates: Requirements 7.1**
        """
        persona = self.get_persona(role)
        variation_phrases = persona.get('variation_phrases', {})
        
        if not variation_phrases:
            return []
        
        phrases = variation_phrases.get(category, {})
        
        if subcategory and isinstance(phrases, dict):
            return phrases.get(subcategory, [])
        elif isinstance(phrases, list):
            return phrases
        
        return []
    
    def get_random_opening(
        self,
        role: str,
        context_type: str = "knowledge",
        exclude_phrases: Optional[List[str]] = None
    ) -> Optional[str]:
        """
        Get a random opening phrase, excluding recently used ones.
        
        Args:
            role: User role
            context_type: Type of response (knowledge, follow_up, empathy)
            exclude_phrases: List of recently used phrases to avoid
            
        Returns:
            A phrase not in exclude_phrases, or None if all exhausted
        """
        import random
        
        phrases = self.get_variation_phrases(role, "openings", context_type)
        
        if not phrases:
            return None
        
        if exclude_phrases:
            available = [p for p in phrases if p not in exclude_phrases]
            if available:
                return random.choice(available)
        
        return random.choice(phrases)
    
    def get_empathy_response_template(
        self,
        role: str,
        empathy_type: str = "frustration"
    ) -> Optional[str]:
        """
        Get empathy response template from YAML.
        
        Args:
            role: User role
            empathy_type: Type of empathy (frustration, basic_needs, encouragement, urgent, busy)
            
        Returns:
            Response template string with placeholders
        """
        persona = self.get_persona(role)
        empathy_patterns = persona.get('empathy_patterns', {})
        empathy_responses = empathy_patterns.get('empathy_responses', {})
        
        return empathy_responses.get(empathy_type)
    
    def reload(self) -> None:
        """Reload all persona files."""
        self._personas = {}
        self._load_personas()
        logger.info("Reloaded all persona configurations")


# Singleton instance
_prompt_loader: Optional[PromptLoader] = None


def get_prompt_loader() -> PromptLoader:
    """Get or create PromptLoader singleton."""
    global _prompt_loader
    if _prompt_loader is None:
        _prompt_loader = PromptLoader()
    return _prompt_loader
