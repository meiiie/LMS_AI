"""
Prompt Loader - Load persona configuration from YAML files.

CH·ªà TH·ªä K·ª∏ THU·∫¨T S·ªê 16: HUMANIZATION
- T√°ch bi·ªát persona ra file YAML
- Few-shot prompting ƒë·ªÉ d·∫°y AI n√≥i chuy·ªán t·ª± nhi√™n
- H·ªó tr·ª£ role-based prompting (student vs teacher/admin)

CH·ªà TH·ªä K·ª∏ THU·∫¨T S·ªê 20: PRONOUN ADAPTATION
- Ph√°t hi·ªán c√°ch x∆∞ng h√¥ t·ª´ user (m√¨nh/c·∫≠u, t·ªõ/c·∫≠u, anh/em, ch·ªã/em)
- AI th√≠ch ·ª©ng x∆∞ng h√¥ theo user
- L·ªçc b·ªè x∆∞ng h√¥ t·ª•c tƒ©u/nh·∫°y c·∫£m

**Feature: maritime-ai-tutor**
**Spec: CH·ªà TH·ªä K·ª∏ THU·∫¨T S·ªê 16, 20**
"""

import logging
import os
import re
from pathlib import Path
from typing import Dict, List, Optional, Any, Tuple

import yaml

logger = logging.getLogger(__name__)


# =============================================================================
# PRONOUN ADAPTATION - CH·ªà TH·ªä K·ª∏ THU·∫¨T S·ªê 20
# =============================================================================

# C√°c c·∫∑p x∆∞ng h√¥ h·ª£p l·ªá (user_pronoun -> ai_pronoun)
VALID_PRONOUN_PAIRS = {
    # User x∆∞ng "m√¨nh" -> AI x∆∞ng "m√¨nh" v√† g·ªçi user l√† "c·∫≠u"
    "m√¨nh": {"user_called": "c·∫≠u", "ai_self": "m√¨nh"},
    # User x∆∞ng "t·ªõ" -> AI x∆∞ng "t·ªõ" v√† g·ªçi user l√† "c·∫≠u"
    "t·ªõ": {"user_called": "c·∫≠u", "ai_self": "t·ªõ"},
    # User x∆∞ng "em" -> AI x∆∞ng "anh/ch·ªã" v√† g·ªçi user l√† "em"
    "em": {"user_called": "em", "ai_self": "anh"},  # Default to "anh", can be "ch·ªã"
    # User x∆∞ng "anh" -> AI x∆∞ng "em" v√† g·ªçi user l√† "anh"
    "anh": {"user_called": "anh", "ai_self": "em"},
    # User x∆∞ng "ch·ªã" -> AI x∆∞ng "em" v√† g·ªçi user l√† "ch·ªã"
    "ch·ªã": {"user_called": "ch·ªã", "ai_self": "em"},
    # User x∆∞ng "t√¥i" -> AI x∆∞ng "t√¥i" v√† g·ªçi user l√† "b·∫°n" (default)
    "t√¥i": {"user_called": "b·∫°n", "ai_self": "t√¥i"},
    # User x∆∞ng "b·∫°n" (g·ªçi AI) -> AI x∆∞ng "t√¥i" v√† g·ªçi user l√† "b·∫°n"
    "b·∫°n": {"user_called": "b·∫°n", "ai_self": "t√¥i"},
}

# T·ª´ x∆∞ng h√¥ t·ª•c tƒ©u/nh·∫°y c·∫£m c·∫ßn l·ªçc b·ªè
INAPPROPRIATE_PRONOUNS = [
    "m√†y", "tao", "ƒë.m", "dm", "vcl", "vl", "ƒë√©o", "ƒë·ªãt",
    "con", "th·∫±ng", "ƒë·ªì", "l≈©", "b·ªçn",  # Khi d√πng m·ªôt m√¨nh c√≥ th·ªÉ x√∫c ph·∫°m
]


def detect_pronoun_style(message: str) -> Optional[Dict[str, str]]:
    """
    Detect user's pronoun style from their message.
    
    CH·ªà TH·ªä K·ª∏ THU·∫¨T S·ªê 20: Pronoun Adaptation
    
    Args:
        message: User's message text
        
    Returns:
        Dict with pronoun style info or None if not detected
        Example: {"user_self": "m√¨nh", "user_called": "c·∫≠u", "ai_self": "m√¨nh"}
        
    **Validates: Requirements 6.1, 6.4**
    """
    message_lower = message.lower()
    
    # Check for inappropriate pronouns first
    for bad_word in INAPPROPRIATE_PRONOUNS:
        if bad_word in message_lower:
            logger.warning(f"Inappropriate pronoun detected: {bad_word}")
            return None  # Reject and use default
    
    # Patterns to detect user's self-reference
    # Order matters: check more specific patterns first
    pronoun_patterns = [
        # "m√¨nh" patterns
        (r'\bm√¨nh\s+(?:l√†|t√™n|mu·ªën|c·∫ßn|h·ªèi|kh√¥ng|c√≥|ƒëang|s·∫Ω|ƒë√£)', "m√¨nh"),
        (r'\bm√¨nh\b', "m√¨nh"),
        # "t·ªõ" patterns
        (r'\bt·ªõ\s+(?:l√†|t√™n|mu·ªën|c·∫ßn|h·ªèi|kh√¥ng|c√≥|ƒëang|s·∫Ω|ƒë√£)', "t·ªõ"),
        (r'\bt·ªõ\b', "t·ªõ"),
        # "em" patterns (user x∆∞ng em v·ªõi AI)
        (r'\bem\s+(?:l√†|t√™n|mu·ªën|c·∫ßn|h·ªèi|kh√¥ng|c√≥|ƒëang|s·∫Ω|ƒë√£|ch√†o)', "em"),
        (r'^em\s+', "em"),  # Message starts with "em"
        # "anh" patterns (user g·ªçi AI l√† anh)
        (r'(?:ch√†o|c·∫£m ∆°n|h·ªèi|nh·ªù)\s+anh\b', "anh"),
        (r'\banh\s+(?:∆°i|√†|nh√©|gi√∫p|ch·ªâ)', "anh"),
        # "ch·ªã" patterns (user g·ªçi AI l√† ch·ªã)
        (r'(?:ch√†o|c·∫£m ∆°n|h·ªèi|nh·ªù)\s+ch·ªã\b', "ch·ªã"),
        (r'\bch·ªã\s+(?:∆°i|√†|nh√©|gi√∫p|ch·ªâ)', "ch·ªã"),
        # "c·∫≠u" patterns (user g·ªçi AI l√† c·∫≠u)
        (r'(?:ch√†o|c·∫£m ∆°n|h·ªèi|nh·ªù)\s+c·∫≠u\b', "m√¨nh"),  # If user calls AI "c·∫≠u", they use "m√¨nh"
        (r'\bc·∫≠u\s+(?:∆°i|√†|nh√©|gi√∫p|ch·ªâ)', "m√¨nh"),
    ]
    
    for pattern, pronoun in pronoun_patterns:
        if re.search(pattern, message_lower):
            if pronoun in VALID_PRONOUN_PAIRS:
                style = VALID_PRONOUN_PAIRS[pronoun].copy()
                style["user_self"] = pronoun
                logger.info(f"Detected pronoun style: {style}")
                return style
    
    return None  # No specific style detected, use default


def get_pronoun_instruction(pronoun_style: Optional[Dict[str, str]]) -> str:
    """
    Generate instruction for AI to use adapted pronouns.
    
    Args:
        pronoun_style: Dict with pronoun style info
        
    Returns:
        Instruction string for system prompt
        
    **Validates: Requirements 6.2**
    """
    if not pronoun_style:
        return ""
    
    user_called = pronoun_style.get("user_called", "b·∫°n")
    ai_self = pronoun_style.get("ai_self", "t√¥i")
    user_self = pronoun_style.get("user_self", "")
    
    instruction = f"""
--- C√ÅCH X∆ØNG H√î ƒê√É TH√çCH ·ª®NG ---
‚ö†Ô∏è QUAN TR·ªåNG: User ƒëang x∆∞ng "{user_self}", h√£y th√≠ch ·ª©ng theo:
- G·ªçi user l√†: "{user_called}"
- T·ª± x∆∞ng l√†: "{ai_self}"
- KH√îNG d√πng "t√¥i/b·∫°n" m·∫∑c ƒë·ªãnh n·ªØa
- Gi·ªØ nh·∫•t qu√°n trong su·ªët cu·ªôc h·ªôi tho·∫°i
"""
    return instruction


class PromptLoader:
    """
    Load and manage persona configurations from YAML files.
    
    Usage:
        loader = PromptLoader()
        prompt = loader.build_system_prompt("student")
    """
    
    def __init__(self, prompts_dir: Optional[str] = None):
        """
        Initialize PromptLoader.
        
        Args:
            prompts_dir: Path to prompts directory. Defaults to app/prompts/
        """
        if prompts_dir:
            self._prompts_dir = Path(prompts_dir)
        else:
            # Default: app/prompts/
            self._prompts_dir = Path(__file__).parent
        
        self._personas: Dict[str, Dict[str, Any]] = {}
        self._load_personas()
    
    def _load_personas(self) -> None:
        """Load all persona YAML files with inheritance support."""
        # Legacy structure (for backward compatibility)
        # FIXED: Updated paths to correct location in agents/ folder
        legacy_files = {
            "student": "agents/tutor.yaml",
            "teacher": "agents/assistant.yaml",
            "admin": "agents/assistant.yaml"
        }
        
        # New SOTA 2025 structure (agents folder)
        new_agent_files = {
            "tutor_agent": "agents/tutor.yaml",
            "assistant_agent": "agents/assistant.yaml",
            "rag_agent": "agents/rag.yaml",
            "memory_agent": "agents/memory.yaml"
        }
        
        # Log prompts directory for debugging deployment issues
        logger.info(f"PromptLoader: Looking for YAML files in {self._prompts_dir}")
        logger.info(f"PromptLoader: Directory exists: {self._prompts_dir.exists()}")
        
        if self._prompts_dir.exists():
            try:
                files_in_dir = list(self._prompts_dir.glob("**/*.yaml"))
                logger.info(f"PromptLoader: Found YAML files: {[str(f.relative_to(self._prompts_dir)) for f in files_in_dir]}")
            except Exception as e:
                logger.warning(f"PromptLoader: Could not list directory: {e}")
        
        # Load shared base config first (for inheritance)
        shared_config = self._load_shared_config()
        
        loaded_count = 0
        
        # Load legacy files first
        for role, filename in legacy_files.items():
            filepath = self._prompts_dir / filename
            if filepath.exists():
                try:
                    with open(filepath, "r", encoding="utf-8") as f:
                        self._personas[role] = yaml.safe_load(f)
                    logger.info(f"‚úÖ Loaded persona for role '{role}' from {filename}")
                    loaded_count += 1
                except Exception as e:
                    logger.error(f"‚ùå Failed to load {filename}: {e}")
                    self._personas[role] = self._get_default_persona()
            else:
                logger.warning(f"‚ö†Ô∏è Persona file not found: {filepath} - using default")
                self._personas[role] = self._get_default_persona()
        
        # Load new agent personas with inheritance
        for agent_id, filename in new_agent_files.items():
            filepath = self._prompts_dir / filename
            if filepath.exists():
                try:
                    with open(filepath, "r", encoding="utf-8") as f:
                        agent_config = yaml.safe_load(f)
                    
                    # Apply inheritance from shared config
                    if agent_config.get("extends"):
                        agent_config = self._merge_with_base(agent_config, shared_config)
                    
                    self._personas[agent_id] = agent_config
                    logger.info(f"‚úÖ Loaded agent persona '{agent_id}' from {filename}")
                    loaded_count += 1
                except Exception as e:
                    logger.error(f"‚ùå Failed to load {filename}: {e}")
        
        logger.info(f"PromptLoader: Loaded {loaded_count} persona files")
    
    def _load_shared_config(self) -> Dict[str, Any]:
        """Load shared base configuration for inheritance."""
        shared_path = self._prompts_dir / "base" / "_shared.yaml"
        if shared_path.exists():
            try:
                with open(shared_path, "r", encoding="utf-8") as f:
                    config = yaml.safe_load(f)
                logger.info("‚úÖ Loaded shared base config from base/_shared.yaml")
                return config
            except Exception as e:
                logger.error(f"‚ùå Failed to load shared config: {e}")
        return {}
    
    def _merge_with_base(
        self, 
        agent_config: Dict[str, Any], 
        base_config: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        Merge agent config with base config (inheritance pattern).
        
        Agent config overrides base config values.
        """
        merged = base_config.copy()
        
        for key, value in agent_config.items():
            if key == "extends":
                continue  # Skip extends key
            elif isinstance(value, dict) and key in merged and isinstance(merged[key], dict):
                # Deep merge for dicts
                merged[key] = {**merged[key], **value}
            else:
                # Override for other types
                merged[key] = value
        
        return merged
    
    def _get_default_persona(self) -> Dict[str, Any]:
        """Get default persona if YAML not found."""
        return {
            "role": "Maritime AI Assistant",
            "tone": ["Th√¢n thi·ªán", "Chuy√™n nghi·ªáp"],
            "instructions": {},
            "few_shot_examples": []
        }
    
    def get_persona(self, role: str) -> Dict[str, Any]:
        """
        Get persona configuration for a role.
        
        Args:
            role: User role (student, teacher, admin)
            
        Returns:
            Persona configuration dict
        """
        return self._personas.get(role, self._personas.get("student", {}))
    
    def _replace_template_variables(
        self,
        text: str,
        user_name: Optional[str] = None,
        **kwargs
    ) -> str:
        """
        Replace template variables in text with actual values.
        
        Supported variables:
        - {{user_name}} -> User's name from Memory
        
        Args:
            text: Text containing template variables
            user_name: User's name to substitute
            **kwargs: Additional variables for future expansion
            
        Returns:
            Text with variables replaced
        """
        if not text:
            return text
        
        # Replace {{user_name}} with actual name or fallback
        if user_name:
            text = text.replace("{{user_name}}", user_name)
        else:
            # Fallback: remove the variable or use generic term
            text = text.replace("{{user_name}}", "b·∫°n")
        
        # Future: Add more template variables here
        # text = text.replace("{{variable}}", value)
        
        return text
    
    def build_thinking_instruction(self, role: str = "student") -> str:
        """
        Build SOTA thinking language instruction from YAML config.
        
        Reads 'thinking' section from _shared.yaml and generates a 
        language enforcement block to be injected at TOP of system prompt.
        
        CH·ªà TH·ªä S·ªê 29 v7: SOTA Vietnamese Thinking
        
        SOTA Pattern (Claude + Qwen3 + OpenAI combined):
        - XML tags for clear language control structure
        - Explicit correct/incorrect examples
        - Language control block at TOP of system prompt
        
        Args:
            role: User role (student, teacher, admin)
            
        Returns:
            Formatted XML-based thinking instruction string
            
        **Validates: CH·ªà TH·ªä S·ªê 29 v7**
        """
        persona = self.get_persona(role)
        thinking = persona.get('thinking', {})
        
        # Default values if not configured
        enforcement = thinking.get('enforcement', 'strict')
        
        # SOTA: Get XML language control block
        language_control_xml = thinking.get('language_control_xml', '''
<language_control>
  <thinking_language>Vietnamese</thinking_language>
  <output_language>Vietnamese</output_language>
  <requirement>ALL internal reasoning MUST be in Vietnamese</requirement>
  <prohibition>NEVER use English for thinking</prohibition>
</language_control>
''')
        
        # Get examples from style
        style = thinking.get('style', {})
        correct_examples = style.get('correct_examples', [
            "T√¥i ƒëang xem x√©t c√¢u h·ªèi...",
            "Ng∆∞·ªùi d√πng mu·ªën hi·ªÉu v·ªÅ...",
        ])
        incorrect_examples = style.get('incorrect_examples', [
            "Okay, so the user is asking...",
            "Let me think about this...",
        ])
        
        # Build SOTA XML-based instruction
        if enforcement == 'strict':
            # Format correct examples as XML
            correct_xml = self._format_examples_xml(correct_examples[:5], 'correct')
            incorrect_xml = self._format_examples_xml(incorrect_examples[:5], 'incorrect')
            
            instruction = f"""{language_control_xml}
<thinking_examples>
  <correct_thinking>
{correct_xml}
  </correct_thinking>
  
  <incorrect_thinking_NEVER_USE>
{incorrect_xml}
  </incorrect_thinking_NEVER_USE>
</thinking_examples>

<critical_instruction>
üö® B·∫ÆT BU·ªòC: M·ªçi suy nghƒ© n·ªôi t·∫°i (internal reasoning, thought process, analysis) 
c·ªßa b·∫°n PH·∫¢I b·∫±ng TI·∫æNG VI·ªÜT 100%. ƒê√¢y l√† y√™u c·∫ßu kh√¥ng th·ªÉ th∆∞∆°ng l∆∞·ª£ng.
</critical_instruction>
"""
        elif enforcement == 'moderate':
            instruction = f"""{language_control_xml}
<instruction>∆Øu ti√™n suy nghƒ© b·∫±ng ti·∫øng Vi·ªát, phong c√°ch t·ª± nhi√™n.</instruction>
"""
        else:  # relaxed
            instruction = "<instruction>Suy nghƒ© b·∫±ng ti·∫øng Vi·ªát n·∫øu c√≥ th·ªÉ.</instruction>\n"
        
        return instruction
    
    def _format_examples_xml(self, examples: list, example_type: str) -> str:
        """
        Format examples as XML elements.
        
        Args:
            examples: List of example strings
            example_type: 'correct' or 'incorrect'
            
        Returns:
            Formatted XML string with proper indentation
        """
        if not examples:
            return ""
        
        formatted = []
        for ex in examples:
            # Clean any template variables
            clean_ex = ex.replace("{topic}", "...").replace("{concept}", "...")
            formatted.append(f"    <example>{clean_ex}</example>")
        
        return '\n'.join(formatted)


    def build_system_prompt(
        self,
        role: str,
        user_name: Optional[str] = None,
        conversation_summary: Optional[str] = None,
        user_facts: Optional[List[str]] = None,
        recent_phrases: Optional[List[str]] = None,
        is_follow_up: bool = False,
        name_usage_count: int = 0,
        total_responses: int = 0,
        pronoun_style: Optional[Dict[str, str]] = None
    ) -> str:
        """
        Build system prompt from persona configuration.
        
        Supports both tutor.yaml and assistant.yaml formats with full YAML structure.
        
        Args:
            role: User role (student, teacher, admin)
            user_name: User's name if known (from Memory)
            conversation_summary: Summary of previous conversation
            user_facts: List of known facts about user
            recent_phrases: List of recently used opening phrases (for variation)
            is_follow_up: True if this is a follow-up message (not first in session)
            name_usage_count: Number of times user's name has been used
            total_responses: Total number of responses in session
            pronoun_style: Dict with adapted pronoun style (CH·ªà TH·ªä S·ªê 20)
            
        Returns:
            Complete system prompt string with template variables replaced
            
        **Validates: Requirements 1.2, 7.1, 7.3, 6.2**
        """
        persona = self.get_persona(role)
        
        # Build prompt sections
        sections = []
        
        # ============================================================
        # CRITICAL RULE AT THE TOP (Most important - LLM sees this first)
        # ============================================================
        sections.append("=" * 60)
        sections.append("‚õî QUY T·∫ÆC TUY·ªÜT ƒê·ªêI - ƒê·ªåC TR∆Ø·ªöC KHI TR·∫¢ L·ªúI ‚õî")
        sections.append("=" * 60)
        sections.append("KH√îNG BAO GI·ªú b·∫Øt ƒë·∫ßu c√¢u tr·∫£ l·ªùi b·∫±ng '√Ä,' ho·∫∑c '√Ä, ' ho·∫∑c '√Ä '")
        sections.append("Thay v√†o ƒë√≥, b·∫Øt ƒë·∫ßu tr·ª±c ti·∫øp b·∫±ng:")
        sections.append("  - '**Quy t·∫Øc X** - ...'")
        sections.append("  - 'Ti·∫øp t·ª•c v·ªõi **Quy t·∫Øc X**...'")
        sections.append("  - 'N√≥i v·ªÅ **Quy t·∫Øc X**...'")
        sections.append("  - 'Chuy·ªÉn sang **Quy t·∫Øc X**...'")
        sections.append("=" * 60)
        sections.append("")
        
        # ============================================================
        # PROFILE SECTION (from YAML profile.*)
        # ============================================================
        profile = persona.get('profile', {})
        if profile:
            profile_name = profile.get('name', 'Maritime AI')
            profile_role = profile.get('role', 'Assistant')
            sections.append(f"B·∫°n l√† **{profile_name}** - {profile_role}.")
            
            if profile.get('backstory'):
                sections.append(f"\n{profile['backstory'].strip()}")
        else:
            # Fallback for old format
            role_name = persona.get('role', 'Maritime AI Assistant')
            sections.append(f"B·∫°n l√† {role_name}.")
            if persona.get('description'):
                sections.append(persona['description'])
        
        # ============================================================
        # STYLE SECTION (from YAML style.*)
        # ============================================================
        style = persona.get('style', {})
        
        # Tone
        tone = style.get('tone') or persona.get('tone', [])
        if tone:
            sections.append("\nGI·ªåNG VƒÇN:")
            for t in tone:
                sections.append(f"- {t}")
        
        # Formatting rules
        formatting = style.get('formatting', [])
        if formatting:
            sections.append("\nƒê·ªäNH D·∫†NG:")
            for f in formatting:
                sections.append(f"- {f}")
        
        # Addressing rules (for assistant.yaml)
        addressing = style.get('addressing_rules', [])
        if addressing:
            sections.append("\nC√ÅCH X∆ØNG H√î:")
            for a in addressing:
                sections.append(f"- {a}")
        
        # ============================================================
        # THOUGHT PROCESS (from YAML thought_process.*)
        # ============================================================
        thought_process = persona.get('thought_process', {})
        if thought_process:
            sections.append("\nQUY TR√åNH SUY NGHƒ® (Tr∆∞·ªõc khi tr·∫£ l·ªùi):")
            for step, instruction in thought_process.items():
                # Format: "1_analyze" -> "1. analyze"
                step_num = step.split('_')[0] if '_' in step else step
                sections.append(f"{step_num}. {instruction}")
        
        # ============================================================
        # CH·ªà TH·ªä S·ªê 21: DEEP REASONING (from YAML deep_reasoning.*)
        # ============================================================
        deep_reasoning = persona.get('deep_reasoning', {})
        if deep_reasoning and deep_reasoning.get('enabled', False):
            sections.append("\n" + "="*60)
            sections.append("üß† DEEP REASONING - T∆Ø DUY N·ªòI T√ÇM (B·∫ÆT BU·ªòC)")
            sections.append("="*60)
            
            # Description
            if deep_reasoning.get('description'):
                sections.append(deep_reasoning['description'].strip())
            
            # Thinking rules
            thinking_rules = deep_reasoning.get('thinking_rules', [])
            if thinking_rules:
                sections.append("\nQUY T·∫ÆC T∆Ø DUY:")
                for rule in thinking_rules:
                    sections.append(f"- {rule}")
            
            # Response format
            if deep_reasoning.get('response_format'):
                sections.append("\nƒê·ªäNH D·∫†NG TR·∫¢ L·ªúI:")
                sections.append(deep_reasoning['response_format'].strip())
            
            # Proactive behavior
            proactive = deep_reasoning.get('proactive_behavior', {})
            if proactive:
                sections.append("\nH√ÄNH VI CH·ª¶ ƒê·ªòNG:")
                if proactive.get('description'):
                    sections.append(proactive['description'].strip())
                if proactive.get('example'):
                    sections.append(f"V√≠ d·ª•: \"{proactive['example']}\"")
            
            sections.append("="*60)
        
        # ============================================================
        # DIRECTIVES SECTION (from YAML directives.*)
        # ============================================================
        directives = persona.get('directives', {})
        if directives:
            if directives.get('dos'):
                sections.append("\nN√äN L√ÄM:")
                for rule in directives['dos']:
                    # Replace template variables like {{user_name}}
                    rule = self._replace_template_variables(rule, user_name)
                    sections.append(f"- {rule}")
            
            if directives.get('donts'):
                sections.append("\nKH√îNG N√äN:")
                for rule in directives['donts']:
                    sections.append(f"- {rule}")
        
        # Instructions (legacy format)
        instructions = persona.get('instructions', {})
        if instructions:
            sections.append("\nQUY T·∫ÆC ·ª®NG X·ª¨:")
            for category, rules in instructions.items():
                if isinstance(rules, list):
                    for rule in rules:
                        sections.append(f"- {rule}")
        
        # ============================================================
        # USER CONTEXT (from Memory - CRITICAL for personalization)
        # ============================================================
        if user_name or user_facts:
            sections.append("\n--- TH√îNG TIN NG∆Ø·ªúI D√ôNG (t·ª´ Memory) ---")
            if user_name:
                sections.append(f"- T√™n: **{user_name}**")
            if user_facts:
                for fact in user_facts[:5]:  # Limit to 5 facts
                    sections.append(f"- {fact}")
        
        # ============================================================
        # CONVERSATION SUMMARY (from MemorySummarizer)
        # ============================================================
        if conversation_summary:
            sections.append(f"\n--- T√ìM T·∫ÆT H·ªòI THO·∫†I TR∆Ø·ªöC ---\n{conversation_summary}")
        
        # ============================================================
        # VARIATION INSTRUCTIONS (Anti-repetition)
        # Spec: ai-response-quality, Requirements 7.1, 7.3
        # ============================================================
        if recent_phrases or is_follow_up or total_responses > 0:
            sections.append("\n--- H∆Ø·ªöNG D·∫™N ƒêA D·∫†NG H√ìA (VARIATION) ---")
            
            # Follow-up instruction
            if is_follow_up:
                sections.append("- ƒê√¢y l√† tin nh·∫Øn FOLLOW-UP, KH√îNG ch√†o h·ªèi l·∫°i.")
            
            # Name usage instruction (20-30% frequency)
            if user_name and total_responses > 0:
                name_ratio = name_usage_count / total_responses if total_responses > 0 else 0
                if name_ratio >= 0.3:
                    sections.append(f"- KH√îNG d√πng t√™n '{user_name}' trong response n√†y (ƒë√£ d√πng ƒë·ªß r·ªìi).")
                elif name_ratio < 0.2:
                    sections.append(f"- C√≥ th·ªÉ d√πng t√™n '{user_name}' m·ªôt c√°ch t·ª± nhi√™n.")
            
            # Phrases to avoid - CRITICAL for anti-repetition
            if recent_phrases:
                sections.append("\n‚ö†Ô∏è C√ÅC C√ÅCH M·ªû ƒê·∫¶U B·∫†N ƒê√É D√ôNG G·∫¶N ƒê√ÇY:")
                for i, phrase in enumerate(recent_phrases[-3:], 1):
                    sections.append(f"  {i}. \"{phrase[:40]}...\"")
                sections.append("‚Üí KH√îNG ƒë∆∞·ª£c b·∫Øt ƒë·∫ßu response b·∫±ng c√°c pattern t∆∞∆°ng t·ª±!")
                sections.append("‚Üí H√£y d√πng c√°ch m·ªü ƒë·∫ßu KH√ÅC BI·ªÜT ho√†n to√†n.")
        
        # ============================================================
        # CRITICAL: ADDRESSING RULES (C√°ch x∆∞ng h√¥ - CH·ªà TH·ªä S·ªê 20)
        # ============================================================
        if pronoun_style:
            # User ƒë√£ c√≥ pronoun style ƒë∆∞·ª£c detect -> th√≠ch ·ª©ng theo
            pronoun_instruction = get_pronoun_instruction(pronoun_style)
            sections.append(pronoun_instruction)
        elif role == "student":
            # M·∫∑c ƒë·ªãnh cho student role
            sections.append("\n--- C√ÅCH X∆ØNG H√î M·∫∂C ƒê·ªäNH ---")
            sections.append("- G·ªçi ng∆∞·ªùi d√πng l√† 'b·∫°n' (l·ªãch s·ª±, th√¢n thi·ªán)")
            sections.append("- T·ª± x∆∞ng l√† 't√¥i'")
            sections.append("- N·∫øu ng∆∞·ªùi d√πng d√πng c√°ch x∆∞ng h√¥ kh√°c (m√¨nh/c·∫≠u, em/anh...) th√¨ TH√çCH ·ª®NG THEO")
            sections.append("- KH√îNG c·ª©ng nh·∫Øc gi·ªØ 't√¥i/b·∫°n' n·∫øu user ƒë√£ ƒë·ªïi c√°ch x∆∞ng h√¥")
        
        # ============================================================
        # CRITICAL: ANTI-REPETITION RULES (QUAN TR·ªåNG NH·∫§T)
        # ============================================================
        sections.append("\n" + "="*60)
        sections.append("‚ö†Ô∏è QUY T·∫ÆC B·∫ÆT BU·ªòC - KH√îNG ƒê∆Ø·ª¢C VI PH·∫†M ‚ö†Ô∏è")
        sections.append("="*60)
        sections.append("1. TUY·ªÜT ƒê·ªêI KH√îNG b·∫Øt ƒë·∫ßu c√¢u tr·∫£ l·ªùi b·∫±ng '√Ä,' ho·∫∑c '√Ä, ' ho·∫∑c '√Ä '")
        sections.append("   - ƒê√¢y l√† th√≥i quen X·∫§U, nghe kh√¥ng chuy√™n nghi·ªáp")
        sections.append("   - Thay v√†o ƒë√≥, b·∫Øt ƒë·∫ßu tr·ª±c ti·∫øp b·∫±ng t√™n quy t·∫Øc ho·∫∑c n·ªôi dung")
        sections.append("2. Khi tr·∫£ l·ªùi nhi·ªÅu c√¢u h·ªèi li√™n ti·∫øp v·ªÅ quy t·∫Øc:")
        sections.append("   - C√¢u 1: B·∫Øt ƒë·∫ßu b·∫±ng '**Quy t·∫Øc X** - ...' ho·∫∑c 'V·ªÅ v·∫•n ƒë·ªÅ n√†y...'")
        sections.append("   - C√¢u 2: B·∫Øt ƒë·∫ßu b·∫±ng 'Quy t·∫Øc n√†y c≈©ng quan tr·ªçng...' ho·∫∑c 'Ti·∫øp theo...'")
        sections.append("   - C√¢u 3: B·∫Øt ƒë·∫ßu b·∫±ng 'N√≥i v·ªÅ **Quy t·∫Øc X**...' ho·∫∑c 'Chuy·ªÉn sang...'")
        sections.append("3. KH√îNG l·∫∑p l·∫°i c√πng m·ªôt c√°ch m·ªü ƒë·∫ßu trong 3 c√¢u li√™n ti·∫øp")
        sections.append("="*60)
        
        # ============================================================
        # TOOLS INSTRUCTION (Required for ReAct Agent)
        # ============================================================
        sections.append("\n--- S·ª¨ D·ª§NG C√îNG C·ª§ (TOOLS) ---")
        sections.append("- H·ªèi v·ªÅ lu·∫≠t h√†ng h·∫£i, quy t·∫Øc, t√†u bi·ªÉn -> B·∫ÆT BU·ªòC g·ªçi `tool_maritime_search`. ƒê·ª™NG b·ªãa.")
        sections.append("- User gi·ªõi thi·ªáu t√™n/tu·ªïi/tr∆∞·ªùng/ngh·ªÅ -> G·ªçi `tool_save_user_info` ƒë·ªÉ ghi nh·ªõ.")
        sections.append("- C·∫ßn bi·∫øt t√™n user -> G·ªçi `tool_get_user_info`.")
        sections.append("- Ch√†o h·ªèi x√£ giao, than v√£n -> Tr·∫£ l·ªùi tr·ª±c ti·∫øp, KH√îNG c·∫ßn tool.")
        
        # ============================================================
        # FEW-SHOT EXAMPLES (from YAML few_shot_examples)
        # ============================================================
        examples = persona.get('few_shot_examples', [])
        if examples:
            sections.append("\n--- V√ç D·ª§ C√ÅCH TR·∫¢ L·ªúI ---")
            for ex in examples[:4]:  # Limit to 4 examples
                context = ex.get('context', '')
                user_msg = ex.get('user', '')
                ai_msg = ex.get('ai', '')
                if user_msg and ai_msg:
                    sections.append(f"\n[{context}]")
                    sections.append(f"User: {user_msg}")
                    sections.append(f"AI: {ai_msg}")
        
        return "\n".join(sections)
    
    def get_fact_extraction_hints(self, role: str) -> Dict[str, List[str]]:
        """
        Get hints for fact extraction (what to extract vs ignore).
        
        Args:
            role: User role
            
        Returns:
            Dict with 'extract' and 'ignore' lists
        """
        persona = self.get_persona(role)
        memory_hints = persona.get('memory_hints', {})
        
        return {
            "extract": memory_hints.get('extract_facts', []),
            "ignore": memory_hints.get('ignore_facts', [])
        }
    
    # =========================================================================
    # ENHANCED METHODS - AI Response Quality Improvement
    # Spec: ai-response-quality, Requirements 1.2, 7.1
    # =========================================================================
    
    def detect_empathy_needed(self, message: str, role: str = "student") -> bool:
        """
        Detect if user message requires empathy-first response.
        
        Checks message against empathy_patterns defined in YAML.
        
        Args:
            message: User's message text
            role: User role to get correct persona
            
        Returns:
            True if empathy response is needed
            
        **Validates: Requirements 1.2**
        """
        persona = self.get_persona(role)
        empathy_patterns = persona.get('empathy_patterns', {})
        
        if not empathy_patterns:
            return False
        
        message_lower = message.lower()
        
        # Check frustration keywords
        frustration_keywords = empathy_patterns.get('frustration_keywords', [])
        for keyword in frustration_keywords:
            if keyword.lower() in message_lower:
                logger.debug(f"Empathy needed: frustration keyword '{keyword}' detected")
                return True
        
        # Check basic needs keywords
        basic_needs = empathy_patterns.get('basic_needs_keywords', [])
        for keyword in basic_needs:
            if keyword.lower() in message_lower:
                logger.debug(f"Empathy needed: basic need '{keyword}' detected")
                return True
        
        # Check work pressure keywords (for teacher/admin)
        work_pressure = empathy_patterns.get('work_pressure_keywords', [])
        for keyword in work_pressure:
            if keyword.lower() in message_lower:
                logger.debug(f"Empathy needed: work pressure '{keyword}' detected")
                return True
        
        return False
    
    def get_variation_phrases(
        self,
        role: str,
        category: str,
        subcategory: Optional[str] = None
    ) -> List[str]:
        """
        Get alternative phrases for a category to avoid repetition.
        
        Args:
            role: User role (student, teacher, admin)
            category: Phrase category (openings, transitions, closings)
            subcategory: Optional subcategory (knowledge, follow_up, empathy)
            
        Returns:
            List of alternative phrases
            
        **Validates: Requirements 7.1**
        """
        persona = self.get_persona(role)
        variation_phrases = persona.get('variation_phrases', {})
        
        if not variation_phrases:
            return []
        
        phrases = variation_phrases.get(category, {})
        
        if subcategory and isinstance(phrases, dict):
            return phrases.get(subcategory, [])
        elif isinstance(phrases, list):
            return phrases
        
        return []
    
    def get_random_opening(
        self,
        role: str,
        context_type: str = "knowledge",
        exclude_phrases: Optional[List[str]] = None
    ) -> Optional[str]:
        """
        Get a random opening phrase, excluding recently used ones.
        
        Args:
            role: User role
            context_type: Type of response (knowledge, follow_up, empathy)
            exclude_phrases: List of recently used phrases to avoid
            
        Returns:
            A phrase not in exclude_phrases, or None if all exhausted
        """
        import random
        
        phrases = self.get_variation_phrases(role, "openings", context_type)
        
        if not phrases:
            return None
        
        if exclude_phrases:
            available = [p for p in phrases if p not in exclude_phrases]
            if available:
                return random.choice(available)
        
        return random.choice(phrases)
    
    def get_empathy_response_template(
        self,
        role: str,
        empathy_type: str = "frustration"
    ) -> Optional[str]:
        """
        Get empathy response template from YAML.
        
        Args:
            role: User role
            empathy_type: Type of empathy (frustration, basic_needs, encouragement, urgent, busy)
            
        Returns:
            Response template string with placeholders
        """
        persona = self.get_persona(role)
        empathy_patterns = persona.get('empathy_patterns', {})
        empathy_responses = empathy_patterns.get('empathy_responses', {})
        
        return empathy_responses.get(empathy_type)
    
    def reload(self) -> None:
        """Reload all persona files."""
        self._personas = {}
        self._load_personas()
        logger.info("Reloaded all persona configurations")


# Singleton instance
_prompt_loader: Optional[PromptLoader] = None


def get_prompt_loader() -> PromptLoader:
    """Get or create PromptLoader singleton."""
    global _prompt_loader
    if _prompt_loader is None:
        _prompt_loader = PromptLoader()
    return _prompt_loader
