"""
Conversation Analyzer - Deep Reasoning & Context Understanding

CHá»ˆ THá»Š Ká»¸ THUáº¬T Sá» 21: DEEP REASONING & SMART CONTEXT ENGINE

PhÃ¢n tÃ­ch ngá»¯ cáº£nh há»™i thoáº¡i Ä‘á»ƒ:
1. Nháº­n diá»‡n cÃ¢u há»i mÆ¡ há»“ (ambiguous questions)
2. LiÃªn káº¿t vá»›i chá»§ Ä‘á» Ä‘ang tháº£o luáº­n
3. PhÃ¡t hiá»‡n giáº£i thÃ­ch dá»Ÿ dang (incomplete explanations)
4. Gá»£i Ã½ proactive behavior cho AI

**Feature: maritime-ai-tutor**
**Spec: CHá»ˆ THá»Š Ká»¸ THUáº¬T Sá» 21**
"""

import logging
import re
from dataclasses import dataclass, field
from typing import Any, Dict, List, Optional
from enum import Enum

logger = logging.getLogger(__name__)


class QuestionType(str, Enum):
    """Types of questions based on context dependency."""
    STANDALONE = "standalone"  # CÃ¢u há»i Ä‘á»™c láº­p, Ä‘á»§ ngá»¯ cáº£nh
    FOLLOW_UP = "follow_up"    # CÃ¢u há»i ná»‘i tiáº¿p, cáº§n ngá»¯ cáº£nh trÆ°á»›c
    AMBIGUOUS = "ambiguous"    # CÃ¢u há»i mÆ¡ há»“, cáº§n suy luáº­n ngá»¯ cáº£nh
    CLARIFICATION = "clarification"  # YÃªu cáº§u lÃ m rÃµ


@dataclass
class ConversationContext:
    """
    Context extracted from conversation history.
    
    Provides hints for AI to understand ambiguous questions.
    """
    # Current topic being discussed
    current_topic: Optional[str] = None
    
    # Last explanation topic (for proactive behavior)
    last_explanation_topic: Optional[str] = None
    
    # Whether AI was explaining something and got interrupted
    should_offer_continuation: bool = False
    
    # Keywords from recent messages
    recent_keywords: List[str] = field(default_factory=list)
    
    # Question type detected
    question_type: QuestionType = QuestionType.STANDALONE
    
    # Inferred context for ambiguous questions
    inferred_context: Optional[str] = None
    
    # Confidence in context inference (0-1)
    confidence: float = 0.0
    
    # Proactive hints for AI
    proactive_hints: List[str] = field(default_factory=list)


class ConversationAnalyzer:
    """
    Analyzes conversation history to provide context for ambiguous questions.
    
    CHá»ˆ THá»Š Ká»¸ THUáº¬T Sá» 21: Deep Reasoning Support
    
    Key features:
    1. Detect ambiguous/follow-up questions
    2. Extract current topic from conversation
    3. Provide context hints for AI reasoning
    4. Detect incomplete explanations for proactive behavior
    """
    
    # Patterns indicating follow-up/ambiguous questions
    FOLLOW_UP_PATTERNS = [
        r"^cÃ²n\s+",           # "CÃ²n X thÃ¬ sao?"
        r"^tháº¿\s+",           # "Tháº¿ X thÃ¬ sao?"
        r"^váº­y\s+",           # "Váº­y X thÃ¬ sao?"
        r"^rá»“i\s+",           # "Rá»“i X thÃ¬ sao?"
        r"\s+thÃ¬ sao\??$",    # "X thÃ¬ sao?"
        r"\s+thÃ¬ tháº¿ nÃ o\??$", # "X thÃ¬ tháº¿ nÃ o?"
        r"^cáº§n\s+",           # "Cáº§n gÃ¬?" (ambiguous)
        r"^phÃ­\s+",           # "PhÃ­ bao nhiÃªu?" (ambiguous)
        r"^bao nhiÃªu\??$",    # "Bao nhiÃªu?"
        r"^nhá»¯ng gÃ¬\??$",     # "Nhá»¯ng gÃ¬?"
        r"^gÃ¬\??$",           # "GÃ¬?"
        r"^sao\??$",          # "Sao?"
    ]
    
    # Patterns indicating standalone questions
    STANDALONE_PATTERNS = [
        r"quy táº¯c\s+\d+",     # "Quy táº¯c 15"
        r"rule\s+\d+",        # "Rule 15"
        r"Ä‘iá»u\s+\d+",        # "Äiá»u 15"
        r"colregs",           # COLREGs
        r"solas",             # SOLAS
        r"marpol",            # MARPOL
        r"lÃ  gÃ¬\??$",         # "X lÃ  gÃ¬?"
        r"giáº£i thÃ­ch",        # "Giáº£i thÃ­ch X"
        r"cho biáº¿t",          # "Cho biáº¿t X"
    ]
    
    # Maritime topic keywords
    MARITIME_TOPICS = {
        "navigation_lights": ["Ä‘Ã¨n", "Ä‘Ã¨n Ä‘á»", "Ä‘Ã¨n xanh", "Ä‘Ã¨n tráº¯ng", "Ä‘Ã¨n vÃ ng", "tÃ­n hiá»‡u", "máº¡n"],
        "ship_registration": ["Ä‘Äƒng kÃ½", "tÃ u biá»ƒn", "giáº¥y tá»", "há»“ sÆ¡", "thá»§ tá»¥c", "phÃ­", "lá»‡ phÃ­"],
        "colregs_rules": ["quy táº¯c", "rule", "colregs", "trÃ¡nh va", "nhÆ°á»ng Ä‘Æ°á»ng"],
        "safety": ["an toÃ n", "solas", "cá»©u sinh", "cá»©u há»a", "phÃ²ng chÃ¡y"],
        "pollution": ["Ã´ nhiá»…m", "marpol", "dáº§u", "rÃ¡c tháº£i", "nÆ°á»›c tháº£i"],
        "navigation": ["hÃ nh trÃ¬nh", "háº£i Ä‘á»“", "Ä‘á»‹nh vá»‹", "gps", "radar"],
    }
    
    def __init__(self):
        """Initialize analyzer."""
        self._compiled_follow_up = [re.compile(p, re.IGNORECASE) for p in self.FOLLOW_UP_PATTERNS]
        self._compiled_standalone = [re.compile(p, re.IGNORECASE) for p in self.STANDALONE_PATTERNS]
        logger.info("ConversationAnalyzer initialized")
    
    def analyze(self, messages: List[Any]) -> ConversationContext:
        """
        Analyze conversation history and extract context.
        
        Args:
            messages: List of message objects with 'role' and 'content' attributes
            
        Returns:
            ConversationContext with extracted information
        """
        context = ConversationContext()
        
        if not messages:
            return context
        
        # Get last user message
        last_user_msg = None
        for msg in reversed(messages):
            role = getattr(msg, 'role', msg.get('role', '')) if isinstance(msg, dict) else msg.role
            if role == "user":
                last_user_msg = getattr(msg, 'content', msg.get('content', '')) if isinstance(msg, dict) else msg.content
                break
        
        if not last_user_msg:
            return context
        
        # Detect question type
        context.question_type = self._detect_question_type(last_user_msg)
        
        # Extract current topic from conversation
        context.current_topic = self._extract_current_topic(messages)
        
        # Extract keywords from recent messages
        context.recent_keywords = self._extract_keywords(messages[-6:])  # Last 3 exchanges
        
        # If ambiguous, try to infer context
        if context.question_type in [QuestionType.AMBIGUOUS, QuestionType.FOLLOW_UP]:
            context.inferred_context = self._infer_context(last_user_msg, messages)
            context.confidence = self._calculate_confidence(context)
            
            # Add proactive hints
            if context.current_topic:
                context.proactive_hints.append(
                    f"CÃ¢u há»i nÃ y cÃ³ thá»ƒ liÃªn quan Ä‘áº¿n chá»§ Ä‘á» '{context.current_topic}' Ä‘ang tháº£o luáº­n."
                )
        
        # Check for incomplete explanations
        context.should_offer_continuation, context.last_explanation_topic = \
            self._detect_incomplete_explanation(messages)
        
        logger.info(f"[ANALYZER] Question type: {context.question_type.value}, "
                   f"Topic: {context.current_topic}, "
                   f"Confidence: {context.confidence:.2f}")
        
        return context
    
    def _detect_question_type(self, message: str) -> QuestionType:
        """Detect the type of question based on patterns."""
        message_lower = message.lower().strip()
        
        # Check for follow-up/ambiguous patterns FIRST (higher priority)
        # These patterns indicate the question depends on previous context
        for pattern in self._compiled_follow_up:
            if pattern.search(message_lower):
                # Short messages are more likely ambiguous
                if len(message_lower.split()) <= 6:
                    return QuestionType.AMBIGUOUS
                return QuestionType.FOLLOW_UP
        
        # Check for standalone patterns
        for pattern in self._compiled_standalone:
            if pattern.search(message_lower):
                return QuestionType.STANDALONE
        
        # Very short messages are likely ambiguous
        if len(message_lower.split()) <= 3:
            return QuestionType.AMBIGUOUS
        
        return QuestionType.STANDALONE
    
    def _extract_current_topic(self, messages: List[Any]) -> Optional[str]:
        """Extract the current topic being discussed."""
        # Look at recent messages for topic keywords
        recent_text = ""
        for msg in messages[-6:]:  # Last 3 exchanges
            content = getattr(msg, 'content', msg.get('content', '')) if isinstance(msg, dict) else msg.content
            recent_text += " " + content.lower()
        
        # Find matching topics
        topic_scores = {}
        for topic, keywords in self.MARITIME_TOPICS.items():
            score = sum(1 for kw in keywords if kw in recent_text)
            if score > 0:
                topic_scores[topic] = score
        
        if topic_scores:
            # Return topic with highest score
            best_topic = max(topic_scores, key=topic_scores.get)
            return best_topic
        
        return None
    
    def _extract_keywords(self, messages: List[Any]) -> List[str]:
        """Extract important keywords from recent messages."""
        keywords = []
        
        for msg in messages:
            content = getattr(msg, 'content', msg.get('content', '')) if isinstance(msg, dict) else msg.content
            content_lower = content.lower()
            
            # Extract maritime keywords
            for topic_keywords in self.MARITIME_TOPICS.values():
                for kw in topic_keywords:
                    if kw in content_lower and kw not in keywords:
                        keywords.append(kw)
        
        return keywords[:10]  # Limit to 10 keywords
    
    def _infer_context(self, current_message: str, messages: List[Any]) -> Optional[str]:
        """
        Infer context for ambiguous questions.
        
        This is the key function for understanding follow-up questions.
        """
        if len(messages) < 2:
            return None
        
        # Get the previous user message and AI response
        prev_user_msg = None
        prev_ai_msg = None
        
        for i in range(len(messages) - 1, -1, -1):
            msg = messages[i]
            role = getattr(msg, 'role', msg.get('role', '')) if isinstance(msg, dict) else msg.role
            content = getattr(msg, 'content', msg.get('content', '')) if isinstance(msg, dict) else msg.content
            
            if role == "assistant" and prev_ai_msg is None:
                prev_ai_msg = content
            elif role == "user" and prev_user_msg is None and content.lower() != current_message.lower():
                prev_user_msg = content
                break
        
        if not prev_user_msg:
            return None
        
        # Build inferred context
        current_lower = current_message.lower()
        
        # Pattern: "CÃ²n X thÃ¬ sao?" -> X is related to previous topic
        if any(p.search(current_lower) for p in self._compiled_follow_up):
            # Extract what user is asking about
            # E.g., "CÃ²n Ä‘Ã¨n xanh thÃ¬ sao?" -> "Ä‘Ã¨n xanh"
            # E.g., "Cáº§n nhá»¯ng giáº¥y tá» gÃ¬?" -> "giáº¥y tá»" related to previous topic
            
            inferred = f"CÃ¢u há»i nÃ y ná»‘i tiáº¿p tá»« cÃ¢u há»i trÆ°á»›c: '{prev_user_msg[:100]}'. "
            
            # Add topic context
            topic = self._extract_current_topic(messages)
            if topic:
                topic_name = {
                    "navigation_lights": "Ä‘Ã¨n tÃ­n hiá»‡u hÃ ng háº£i",
                    "ship_registration": "Ä‘Äƒng kÃ½ tÃ u biá»ƒn",
                    "colregs_rules": "quy táº¯c COLREGs",
                    "safety": "an toÃ n hÃ ng háº£i",
                    "pollution": "phÃ²ng chá»‘ng Ã´ nhiá»…m",
                    "navigation": "hÃ nh trÃ¬nh",
                }.get(topic, topic)
                
                inferred += f"Chá»§ Ä‘á» Ä‘ang tháº£o luáº­n: {topic_name}."
            
            return inferred
        
        return None
    
    def _calculate_confidence(self, context: ConversationContext) -> float:
        """Calculate confidence in context inference."""
        confidence = 0.0
        
        # Has current topic
        if context.current_topic:
            confidence += 0.4
        
        # Has inferred context
        if context.inferred_context:
            confidence += 0.3
        
        # Has recent keywords
        if len(context.recent_keywords) >= 3:
            confidence += 0.2
        elif len(context.recent_keywords) >= 1:
            confidence += 0.1
        
        return min(confidence, 1.0)
    
    def _detect_incomplete_explanation(self, messages: List[Any]) -> tuple[bool, Optional[str]]:
        """
        Detect if AI was explaining something and got interrupted.
        
        Returns:
            (should_offer_continuation, last_explanation_topic)
        """
        if len(messages) < 3:
            return False, None
        
        # Look for patterns indicating incomplete explanation
        # E.g., AI was explaining Rule 15, user asked about something else
        
        last_ai_msg = None
        for msg in reversed(messages[:-1]):  # Exclude current message
            role = getattr(msg, 'role', msg.get('role', '')) if isinstance(msg, dict) else msg.role
            if role == "assistant":
                last_ai_msg = getattr(msg, 'content', msg.get('content', '')) if isinstance(msg, dict) else msg.content
                break
        
        if not last_ai_msg:
            return False, None
        
        # Check if AI was explaining something
        explanation_patterns = [
            r"quy táº¯c\s+(\d+)",
            r"rule\s+(\d+)",
            r"Ä‘iá»u\s+(\d+)",
            r"vá»\s+(.+?)(?:\.|,|:)",
        ]
        
        for pattern in explanation_patterns:
            match = re.search(pattern, last_ai_msg.lower())
            if match:
                topic = match.group(1) if match.lastindex else match.group(0)
                # Check if current question is about a different topic
                # (This is a simplified check)
                return True, topic
        
        return False, None
    
    def build_context_prompt(self, context: ConversationContext) -> str:
        """
        Build a context prompt to inject into AI's thinking.
        
        This helps AI understand ambiguous questions.
        """
        if context.question_type == QuestionType.STANDALONE:
            return ""
        
        prompt_parts = []
        
        prompt_parts.append("[CONTEXT ANALYSIS]")
        
        if context.question_type == QuestionType.AMBIGUOUS:
            prompt_parts.append("âš ï¸ ÄÃ¢y lÃ  cÃ¢u há»i MÆ  Há»’, cáº§n suy luáº­n tá»« ngá»¯ cáº£nh há»™i thoáº¡i.")
        elif context.question_type == QuestionType.FOLLOW_UP:
            prompt_parts.append("ðŸ“Ž ÄÃ¢y lÃ  cÃ¢u há»i Ná»I TIáº¾P tá»« chá»§ Ä‘á» trÆ°á»›c.")
        
        if context.inferred_context:
            prompt_parts.append(f"ðŸ’¡ Suy luáº­n: {context.inferred_context}")
        
        if context.current_topic:
            prompt_parts.append(f"ðŸ“Œ Chá»§ Ä‘á» hiá»‡n táº¡i: {context.current_topic}")
        
        if context.recent_keywords:
            prompt_parts.append(f"ðŸ”‘ Tá»« khÃ³a gáº§n Ä‘Ã¢y: {', '.join(context.recent_keywords[:5])}")
        
        if context.proactive_hints:
            for hint in context.proactive_hints:
                prompt_parts.append(f"ðŸ’¬ {hint}")
        
        prompt_parts.append("[/CONTEXT ANALYSIS]")
        
        return "\n".join(prompt_parts)


# Singleton
_conversation_analyzer: Optional[ConversationAnalyzer] = None


def get_conversation_analyzer() -> ConversationAnalyzer:
    """Get or create ConversationAnalyzer singleton."""
    global _conversation_analyzer
    if _conversation_analyzer is None:
        _conversation_analyzer = ConversationAnalyzer()
    return _conversation_analyzer
