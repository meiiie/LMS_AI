# ğŸ“‹ YÃŠU Cáº¦U: Streaming API cho AI Chat

**NgÃ y:** 10/12/2025  
**Tá»«:** Team LMS Backend  
**Gá»­i:** Team AI Backend  
**Äá»™ Æ°u tiÃªn:** Cao

---

## 1. MÃ” Táº¢ YÃŠU Cáº¦U

Hiá»‡n táº¡i API `/api/v1/chat/` tráº£ vá» **toÃ n bá»™ response má»™t láº§n** sau khi AI xá»­ lÃ½ xong (5-15 giÃ¢y).

ChÃºng tÃ´i muá»‘n implement **Streaming Response** (Server-Sent Events) Ä‘á»ƒ:
- User tháº¥y text xuáº¥t hiá»‡n **tá»«ng chá»¯ má»™t** nhÆ° ChatGPT/Claude
- Cáº£i thiá»‡n UX Ä‘Ã¡ng ká»ƒ - user khÃ´ng pháº£i Ä‘á»£i mÃ n hÃ¬nh trá»‘ng
- Hiá»ƒn thá»‹ quÃ¡ trÃ¬nh suy luáº­n (`<thinking>`) real-time

---

## 2. Äá»€ XUáº¤T API Má»šI

### Endpoint: `POST /api/v1/chat/stream`

**Request:** (Giá»‘ng `/api/v1/chat/`)
```json
{
  "user_id": "550e8400-e29b-41d4-a716-446655440000",
  "message": "Äiá»u 15 Luáº­t HÃ ng háº£i 2015 lÃ  gÃ¬?",
  "role": "student",
  "session_id": "abc12345-e29b-41d4-a716-446655440001"
}
```

**Response:** `Content-Type: text/event-stream`

```
event: thinking
data: {"content": "NgÆ°á»i dÃ¹ng há»i vá» Äiá»u 15..."}

event: thinking
data: {"content": "TÃ´i cáº§n tra cá»©u database..."}

event: answer
data: {"content": "**Äiá»u 15** cá»§a Bá»™ luáº­t"}

event: answer
data: {"content": " HÃ ng háº£i Viá»‡t Nam 2015"}

event: answer
data: {"content": " quy Ä‘á»‹nh vá» chá»§ tÃ u..."}

event: sources
data: {"sources": [...]}

event: suggested_questions
data: {"questions": ["Thuyá»n viÃªn cáº§n Ä‘iá»u kiá»‡n gÃ¬?", ...]}

event: metadata
data: {"processing_time": 5.234, "model": "maritime-rag-v1"}

event: done
data: {}
```

---

## 3. EVENT TYPES

| Event | Description | Khi nÃ o gá»­i |
|-------|-------------|-------------|
| `thinking` | QuÃ¡ trÃ¬nh suy luáº­n | Äáº§u tiÃªn (náº¿u cÃ³) |
| `answer` | Ná»™i dung cÃ¢u tráº£ lá»i | Tá»«ng chunk text |
| `sources` | Nguá»“n tham kháº£o | Sau khi answer xong |
| `suggested_questions` | CÃ¢u há»i gá»£i Ã½ | Sau sources |
| `metadata` | ThÃ´ng tin xá»­ lÃ½ | Cuá»‘i cÃ¹ng |
| `done` | Káº¿t thÃºc stream | Cuá»‘i cÃ¹ng |
| `error` | Lá»—i xáº£y ra | Khi cÃ³ lá»—i |

---

## 4. Lá»¢I ÃCH

| Metric | Hiá»‡n táº¡i | Vá»›i Streaming |
|--------|----------|---------------|
| Time to First Byte | 5-15s | < 500ms |
| Perceived Performance | Cháº­m | Nhanh |
| User Experience | Äá»£i mÃ n hÃ¬nh trá»‘ng | Tháº¥y AI "Ä‘ang nghÄ©" |

---

## 5. IMPLEMENTATION NOTES

### Python FastAPI Example:
```python
from fastapi import FastAPI
from fastapi.responses import StreamingResponse
import asyncio

@app.post("/api/v1/chat/stream")
async def chat_stream(request: ChatRequest):
    async def generate():
        # Thinking phase
        yield f"event: thinking\ndata: {json.dumps({'content': 'Äang phÃ¢n tÃ­ch...'})}\n\n"
        
        # Stream answer chunks
        async for chunk in llm.stream(request.message):
            yield f"event: answer\ndata: {json.dumps({'content': chunk})}\n\n"
        
        # Sources
        yield f"event: sources\ndata: {json.dumps({'sources': sources})}\n\n"
        
        # Done
        yield f"event: done\ndata: {{}}\n\n"
    
    return StreamingResponse(generate(), media_type="text/event-stream")
```

### Spring Boot (LMS Backend) sáº½ forward stream:
```java
@PostMapping(value = "/chat/stream", produces = MediaType.TEXT_EVENT_STREAM_VALUE)
public Flux<ServerSentEvent<String>> chatStream(@RequestBody ChatRequest request) {
    return aiServiceClient.streamChat(request);
}
```

---

## 6. TIMELINE Äá»€ XUáº¤T

| Phase | Task | Thá»i gian |
|-------|------|-----------|
| 1 | Team AI implement streaming endpoint | 2-3 ngÃ y |
| 2 | Team LMS update backend proxy | 1 ngÃ y |
| 3 | Team LMS update frontend | 1 ngÃ y |
| 4 | Integration testing | 1 ngÃ y |

---

## 7. CÃ‚U Há»I CHO TEAM AI

1. **CÃ³ thá»ƒ implement streaming endpoint khÃ´ng?**
2. **Thá»i gian dá»± kiáº¿n?**
3. **CÃ³ cáº§n thay Ä‘á»•i gÃ¬ vá» authentication?**
4. **LLM backend (OpenAI/Anthropic) cÃ³ há»— trá»£ streaming khÃ´ng?**

---

**Xin pháº£n há»“i sá»›m Ä‘á»ƒ chÃºng tÃ´i lÃªn káº¿ hoáº¡ch implementation.**

*Team LMS Backend*
